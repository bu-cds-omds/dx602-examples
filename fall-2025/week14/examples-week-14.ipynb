{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be507e78",
   "metadata": {},
   "source": [
    "Text Analysis\n",
    "\n",
    "... in which we open a file for reading; <br>\n",
    "count the number of total words and unique words;<br>\n",
    "and produce word counts using a dict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e33860",
   "metadata": {},
   "source": [
    "In this first cell, we have 2 ways to access the text data:\n",
    "- (a) in a local file on disk\n",
    "- (b) from a remote website\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db22bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## (A) if working with a local file on your disk: \n",
    "# open a file for reading:\n",
    "# filename = 'time.txt' # Time\n",
    "# # filename = 'romeo.txt' # Romeo and Juliet\n",
    "# filename = 'grapes.txt' # Grapes of Wrath\n",
    "# f = open(filename, 'r')\n",
    "# read all text, split into list of words:\n",
    "# text = f.read()\n",
    "\n",
    "## (B) working with a remote file, download from WWW:\n",
    "import requests \n",
    "# url_time = \"https://raw.githubusercontent.com/bu-cds-omds/dx602-examples/refs/heads/main/data/time.txt\" # Time\n",
    "# response = requests.get(url_time)\n",
    "url_romeo = \"https://raw.githubusercontent.com/bu-cds-omds/dx602-examples/refs/heads/main/data/romeo.txt\"  # Romeo and Juliet\n",
    "response = requests.get(url_romeo)\n",
    "# url_grapes = \"https://raw.githubusercontent.com/bu-cds-omds/dx602-examples/refs/heads/main/data/grapes.txt\" # Grapes of Wrath\n",
    "\n",
    "text = response.content\n",
    "# print(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9261cb",
   "metadata": {},
   "source": [
    "Let's examine this text:\n",
    "- Find total count of words\n",
    "- Use a dictionary to count unique words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f399fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6276 total words.\n",
      "Found 2467 distinct total words.\n",
      "word: the, count: 180\n",
      "word: of, count: 144\n",
      "word: I, count: 134\n",
      "word: and, count: 117\n",
      "word: a, count: 102\n",
      "word: to, count: 92\n",
      "word: in, count: 76\n",
      "word: my, count: 72\n",
      "word: is, count: 67\n",
      "word: you, count: 60\n"
     ]
    }
   ],
   "source": [
    "# split into a list of words:\n",
    "words = text.split() # split based on white space\n",
    "# str.strip() # remove whitespace\n",
    "# words = [str(w.lower()) for w in words]\n",
    "words = [w.decode('utf-8') for w in words]\n",
    "# print(words)\n",
    "print(f\"Found {len(words)} total words.\")\n",
    "\n",
    "# number of distinct words:\n",
    "distinct_words = set(words)\n",
    "print(f\"Found {len(distinct_words)} distinct total words.\")\n",
    "\n",
    "# word counts: how many times does each word occur?\n",
    "# go through each `distinct_words`, and count occurences in `words`\n",
    "word_counts = {} # empty dictionary\n",
    "for w in distinct_words:\n",
    "    # store the count with the word:\n",
    "    word_counts[w] = words.count(w)\n",
    "\n",
    "# show the dictionary of word counts:\n",
    "#print(word_counts)\n",
    "\n",
    "# which words occur most frequently?\n",
    "pairs = list(word_counts.items())\n",
    "\n",
    "pairs = sorted(pairs, key=lambda x: x[1], reverse=True)\n",
    "# print(pairs)\n",
    "# print out the top 10 most frequent occurring words:\n",
    "for i in range(10):\n",
    "    item = pairs[i]\n",
    "    print(f'word: {item[0]}, count: {item[1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454798ca",
   "metadata": {},
   "source": [
    "**First order Markov model**\n",
    "\n",
    "... in which we track words (from original text) and the list of words that can follow each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af528a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a dictionary to hold our Markov model\n",
    "model = {}\n",
    "\n",
    "# assume the first word\n",
    "# current_word = words[0]\n",
    "current_word = \"$\" # special symbol for \"start of sentence\"\n",
    "\n",
    "# loop over all remaining words:\n",
    "# for next_word in words[1:]:\n",
    "for next_word in words:\n",
    "\n",
    "    # add this sequence to our dictionary\n",
    "    # building a list of words that can follow `current_word`\n",
    "    # print(f'{current_word} -> {next_word}')\n",
    "\n",
    "    # check: have we seen `current_word` before?\n",
    "    if current_word in model:\n",
    "        # append to the list of words that can follow `current_word`\n",
    "        follow_words = model[current_word]\n",
    "        follow_words.append(next_word)\n",
    "    else:\n",
    "        # insert into the dictionary (first time we see `current_word`)\n",
    "        model[current_word] = [next_word]\n",
    "\n",
    "    # when we get to the end of a sentence, the next word is a sentence-starting word\n",
    "    # if next_word[-1] in '.?!': # example: 'to end.'\n",
    "    if '.' in next_word or '!' in next_word or '?' in next_word: \n",
    "        current_word = '$' # sentence-starting word follows\n",
    "    else:\n",
    "        # advance to the next word:\n",
    "        current_word = next_word\n",
    "\n",
    "# print(model)\n",
    "# for w in model:\n",
    "#     print(f'{w}: {model[w]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f718b01",
   "metadata": {},
   "source": [
    "**Generating Text (unintelligently)**\n",
    "\n",
    "... in which we use our Markov model of the text to generate new text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d08edbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CITIZENS: Clubs, bills, and they do with sweetmeats tainted are: Sometime she be fourteen; That dreamers often lie. saw you do, sir, in good mark-man!- "
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# start with sentence-starting word:\n",
    "current_word = '$'\n",
    "\n",
    "# do this N times to generate N words\n",
    "for i in range(25):\n",
    "\n",
    "    # find the words that can follow `current_word`\n",
    "    follow_words = model[current_word]\n",
    "\n",
    "    # pick one word from that list -- unintelligently!!\n",
    "    next_word = random.choice(follow_words)\n",
    "    print(next_word, end=' ')\n",
    "\n",
    "    # advance the `current_word`\n",
    "    # when we get to the end of a sentence, the next word is a sentence-starting word\n",
    "    # if next_word[-1] in '.?!': # example: 'to end.'\n",
    "    if '.' in next_word or '!' in next_word or '?' in next_word: \n",
    "        current_word = '$' # sentence-starting word follows\n",
    "    else:\n",
    "        # advance to the next word:\n",
    "        current_word = next_word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
