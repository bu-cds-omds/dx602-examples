{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9NlAdDV9l2U"
      },
      "source": [
        "# Video: Standardizing Data with Scikit-Learn\n",
        "\n",
        "This video shows how to standardize a data set with scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78rpl1rXcPbe"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XLMaY4V9cSDg"
      },
      "outputs": [],
      "source": [
        "abalone = pd.read_csv(\"https://raw.githubusercontent.com/bu-cds-omds/dx602-examples/main/data/abalone.tsv\", sep=\"\\t\")\n",
        "abalone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM1sIrfEgiwx"
      },
      "source": [
        "Script:\n",
        "* Here's our usual abalone dataset.\n",
        "* If we look at some basic summary statistics, the scale varies significantly by column.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oeXROrWxciwu"
      },
      "outputs": [],
      "source": [
        "abalone.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7th-WDE9iCA4"
      },
      "source": [
        "Script:\n",
        "* The rings column has the highest standard deviation, over three.\n",
        "* The next highest is whole weight which is just under one half.\n",
        "* And the smallest standard deviation is for height which is just 0.04.\n",
        "* Some kinds of models are affected a lot by these scale differences, so let's try standardize them.\n",
        "* First, we will drop the Sex column since the standardization only works with numbers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YmqEkj0JfMG3"
      },
      "outputs": [],
      "source": [
        "abalone = abalone.drop(\"Sex\", axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPiIqHg4ilSA"
      },
      "source": [
        "Script:\n",
        "* Then we will compute the mean and standard deviation of each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_klt0elctUE"
      },
      "outputs": [],
      "source": [
        "abalone_mean = abalone.mean(axis=0)\n",
        "abalone_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RazHJM7mc3D8"
      },
      "outputs": [],
      "source": [
        "abalone_std = abalone.std(axis=0)\n",
        "abalone_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZTFmz9bi5C5"
      },
      "source": [
        "Script:\n",
        "* And now we can compute a new version, standardized to mean zero and standard deviation one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koxYZDu-c9WC"
      },
      "outputs": [],
      "source": [
        "abalone_standardized = (abalone - abalone_mean) / abalone_std\n",
        "abalone_standardized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WELQOeairra"
      },
      "source": [
        "Script:\n",
        "* An earlier draft of this code skipped dropping the Sex column and used the numeric_only option for mean and std.\n",
        "* However, the Sex column that resulted was all Not a Number values.\n",
        "* And since that column is a string, the usual tweaks for missing data do not work so well.\n",
        "* Generally, you will want to deal with non-numeric columns first before neatening up the numbers.\n",
        "* Let's sanity check the result of standardization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okIkz4M0eQU6"
      },
      "outputs": [],
      "source": [
        "abalone_standardized.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dutImUz5jjfx"
      },
      "source": [
        "Script:\n",
        "* The mean column doesn't look like zero at first glance, but if you look closely, the exponents range from -16 to -18.\n",
        "* So these are all very small numbers close to zero.\n",
        "* We are seeing the results of numerical imprecision here, and the mean is zero for practical purposes.\n",
        "* For the standard deviation row, all the numbers are one.\n",
        "* So there were fewer numerical issues here.\n",
        "* Looks like the transformation worked.\n",
        "* One question you might have about this transformation is why I broke it down into three steps.\n",
        "* Could I not have done it in one expression like this?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02tEJwnsfXKx"
      },
      "outputs": [],
      "source": [
        "(abalone - abalone.mean(axis=0)) / abalone.std(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MsAqmZPkMCF"
      },
      "source": [
        "Script:\n",
        "* I can do this calculation, but then I have not saved the mean and standard deviation to transform new data later.\n",
        "* When we are running this process later, we will want to subtract the same means and standard deviations that we just used.\n",
        "* We do not want to use the means and standard deviations of the new data, because the transformation will keep changing and not match how we built the model.\n",
        "* This gets particularly inane when we look at one new row of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meKmIuMJkv4l"
      },
      "outputs": [],
      "source": [
        "new_abalone = abalone.iloc[0:1]\n",
        "new_abalone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azL7Id-rk6Yx"
      },
      "source": [
        "Script:\n",
        "* Pretend this is a fresh row of data.\n",
        "* What happens when we subtract the mean?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uAwBO-D9lAWt"
      },
      "outputs": [],
      "source": [
        "new_abalone - new_abalone.mean(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_Vh--QIlLgx"
      },
      "source": [
        "Script:\n",
        "* Subtracting the mean from a new batch of data with one row will give all zeros.\n",
        "* And the standard deviation will be undefined or zero depending on whether you are diligent about your sample adjustment.\n",
        "* Either way, the calculation does not work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi7ZUElOlaNN"
      },
      "outputs": [],
      "source": [
        "(new_abalone - new_abalone.mean(axis=0)) / new_abalone.std(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9uklo7Jld5q"
      },
      "source": [
        "Script:\n",
        "* The proper way to do these transformations is to save the means and standard deviations, so the transformation is consistent between training and later predictions.\n",
        "* Scikit-learn has a built-in preprocessing class called StandardScaler which does this for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKPn5S59e5jM"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRbCb6cte7IG"
      },
      "outputs": [],
      "source": [
        "standardize_transform = StandardScaler()\n",
        "standardize_transform.fit(abalone)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9l06y9ifkOb"
      },
      "outputs": [],
      "source": [
        "standardize_transform.transform(abalone)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1cDk7N6lmCV"
      },
      "source": [
        "Script:\n",
        "* The output that you get back from using the scikit-learn StandardScaler is a numpy array, so the column names are lost, but usually that is ok since this will just be a temporary result.\n",
        "* And it is very convenient for scikit-learn to track the standardization data for you."
      ]
    }
  ],
  "metadata": {
    "colab": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}