{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeGvVFl17S4q"
      },
      "source": [
        "# Video: Validation Sets for Early Stopping\n",
        "\n",
        "This video demonstrates the use of validation sets to decide when to stop training a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU85VFaOgQZt"
      },
      "source": [
        "## Epoch Training\n",
        "\n",
        "Some models are able to keep improving by repeatedly fitting the training data.\n",
        "* Neural networks keep updating weights to reduce errors.\n",
        "* Gradient boosted trees add more trees focused on fixing errors.\n",
        "* Each round of fitting the whole train set is called an \"epoch\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qynSNeHPh6Zd"
      },
      "source": [
        "Script:\n",
        "* Some kinds of models can keep improving their training error until they perfectly fit their training data if you keep trying to fit them.\n",
        "* Neural networks are the best known example of this.\n",
        "* If you repeatedly try to fit a training set and the neural network has enough parameters, it will usually fit the training set perfectly if you are patient enough.\n",
        "* Other algorithms use a technique called \"boosting\" where they repeatedly focus on fitting small models to the current errors, and will slowly reduce overall errors.\n",
        "* But the overall model gets slower as the number of small models that it uses gets bigger.\n",
        "* These methods will be covered in later modules, so you don't need to remember these details now.\n",
        "* The one bit you need to know is that these kinds of models let you keep trying to improve training error, and will improve more as you try longer.\n",
        "* Perhaps fittingly, each round of trying is called an epoch in reference to the unit of geological time, as this process can take a very long time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeBIJnaFfGyG"
      },
      "source": [
        "## What is Early Stopping?\n",
        "\n",
        "* Training in epochs reduces training error over time.\n",
        "* Early epochs tend to fix big/broad mistakes.\n",
        "  * Usually generalizing.\n",
        "* Later epochs tend to fix small/narrow mistakes.\n",
        "  * Usually overfitting.\n",
        "* Early stopping tries to stop at the transition from generalizing to overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3SwtzUXjuwo"
      },
      "source": [
        "Script:\n",
        "* Early stopping aims to try harder as long as the model continues to generalize better, but stop when it is just overfitting.\n",
        "* Usually these epoch-based training process tend to improve their training loss and generalization early on, but eventually generalization flattens out, or even gets worse.\n",
        "* Early stopping tries to catch this transition rather than hoping a preset number of epochs is just right.\n",
        "* How does it work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKBJeGIy9SDs"
      },
      "source": [
        "## How Does Early Stopping Work?\n",
        "\n",
        "Validation sets!\n",
        "* Check validation loss after each epoch.\n",
        "* If a few epochs pass without a meaningful improvement, stop."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HtJN7NIkcQJ"
      },
      "source": [
        "Script:\n",
        "* Of course, the way this work is through validation sets.\n",
        "* After each epoch, the validation loss is checked.\n",
        "* And if it stops improving meaningfully for a few epochs, the training process is stopped.\n",
        "* The assumption is that the test loss will stop improving around the same number of epochs, so checking the validation loss will help us get close to the ideal number of epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDAN3YgX64KT"
      },
      "source": [
        "## Scikit-Learn Support\n",
        "\n",
        "Preview from later modules:\n",
        "* `GradientBoostingRegressor` => `n_iter_no_change`, `tol`\n",
        "* `MLPRegressor` => `early_stopping`, `n_iter_no_change`, `tol`\n",
        "* Automatic validation set if early stopping is enabled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS5xpI_QmDNl"
      },
      "source": [
        "Script:\n",
        "* Wrapping up, scikit-learn has support for this early stopping behavior.\n",
        "* And it automatically creates a validation set if you use early stopping.\n",
        "* Again, you do not need to learn these classes now, but I will show you a quick example now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCFd49vHmSW9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wa3jY1dmNsu"
      },
      "outputs": [],
      "source": [
        "abalone = pd.read_csv(\"https://raw.githubusercontent.com/bu-cds-omds/dx602-examples/main/data/abalone.tsv\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wd2agCKVmW73"
      },
      "outputs": [],
      "source": [
        "abalone_target = abalone[\"Rings\"]\n",
        "abalone_features = abalone.drop([\"Rings\", \"Sex\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jE4QKMdnTeH"
      },
      "outputs": [],
      "source": [
        "train_features, test_features, train_target, test_target = train_test_split(abalone_features, abalone_target, test_size=0.2, random_state=2024)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7ZTrPd-pptg"
      },
      "source": [
        "Script:\n",
        "* I'll show you a quick example with gradient boosting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_9PvLrtmrO5"
      },
      "outputs": [],
      "source": [
        "import sklearn.ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmfG6JWPmtPH",
        "outputId": "52bf8892-4dbb-4aca-f995-5fbae60eceea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.3996592381771311"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "no_stop_model = sklearn.ensemble.GradientBoostingRegressor(n_estimators=1000, max_depth=5, random_state=42)\n",
        "no_stop_model.fit(train_features, train_target)\n",
        "no_stop_model.score(test_features, test_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SablTNJIpy_F"
      },
      "source": [
        "Script:\n",
        "* This is better than most of the decision tree models that we've seen this week, but substantially worse than linear regressions which we have seen get an $R^2$ score of 48% on this dataset.\n",
        "* Let's repeat with early stopping."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQWuCRaWn3H6",
        "outputId": "9791e556-66b7-438e-a0ea-9320e97b76f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.4988235292110631"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "early_stop_model = sklearn.ensemble.GradientBoostingRegressor(n_estimators=1000, max_depth=5, random_state=42, n_iter_no_change=10)\n",
        "early_stop_model.fit(train_features, train_target)\n",
        "early_stop_model.score(test_features, test_target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIhyNE9wqWMB"
      },
      "source": [
        "Script:\n",
        "* And the early stopping model got an $R^2$ of 50%, slightly beating out the linear regression.\n",
        "* How many trees did it use?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28tDeEcOoE-g",
        "outputId": "1056821b-caf5-4dc6-9905-42af4579c689"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "57"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "early_stop_model.n_estimators_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeC7-QDsqusc"
      },
      "source": [
        "Script:\n",
        "* 57 trees, vs 1000 of the previous model.\n",
        "* How much faster is that?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CVNqUfmq3Lo",
        "outputId": "8a648000-e1ba-4431-c0e6-dc3c5f4ba961"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "17.54385964912281"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "1000 / 57"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqBr8XKTq5Gw"
      },
      "source": [
        "Script:\n",
        "* So early stopping gave a better model that runs 17 times faster.\n",
        "* Using the validation set made this work."
      ]
    }
  ],
  "metadata": {
    "colab": {},
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}